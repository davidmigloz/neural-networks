%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% P2 Self-organizing Map
% David Miguel Lozano
% Javier Martínez Riberas
% Universidad de Burgos - Octubre 2016
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% -------------------------------------------------------------
% Preamble
% -------------------------------------------------------------
\documentclass[a4paper,12pt,titlepage]{article}

% -------------------------------------------------------------
% Packages
% -------------------------------------------------------------
\usepackage[utf8]{inputenc}	% Unicode support
\usepackage[T1]{fontenc}		% Font encoding
\usepackage[spanish]{babel}	% Languaje
\usepackage{lmodern}	% Typeface 
\usepackage{textcomp} % Special symbols
\usepackage{graphicx}	% Add pictures
\usepackage{pgfplots} % Graphs and charts
\usepackage{hyperref}	% Add a link to index entries
\usepackage{amsmath}	% Advanced math typesetting
\usepackage{amsfonts}	% Mathematical formulas
\usepackage{amssymb}	% Extended symbol collection
\usepackage{listings}	% Code formatting and highlighting
\usepackage{xcolor}		% Color package
\usepackage{enumitem}	% Customizing lists
\usepackage{parskip}	% Paragraph styles
\usepackage[a4paper]{geometry} 		% Margins
\usepackage[numbers,sort]{natbib}	% Bibliography management
\usepackage{booktabs}							% Tables

% -------------------------------------------------------------
% Configuration
% -------------------------------------------------------------
% Images path
\graphicspath{ {img/} }
% Graphs configuration 
\pgfplotsset{width=\textwidth,compat=1.9}
% Hyperlinks coloring
\hypersetup{
	colorlinks,
	linkcolor={green!40!black},
	citecolor={blue!50!black},
	urlcolor={blue!80!black}
}
% Define HRule
\newcommand{\HRule}[1]{\rule{\linewidth}{#1}}
% Define listings styles
\definecolor{codebg}{HTML}{EEEEEE}
\definecolor{codeframe}{HTML}{CCCCCC}
\definecolor{comments}{HTML}{009900}
\lstset{
  language=Matlab, 								% Programming language 
  backgroundcolor=\color{codebg},	% Background color
  frame=single, 									% Add frame around code
	framesep=10pt,									% Padding
	rulecolor=\color{codeframe},		% Don't change frame color
	upquote=true,										%
	breakatwhitespace=true,					% Break line only in spaces
	keepspaces=true,								% Keep indentation
	tabsize=2,											% Tab size
	title=\lstname, 								% Show filename as caption
	basicstyle=\ttfamily, 					% Size and font
  keywordstyle=\color{blue}\ttfamily,
	commentstyle=\color{comments},	% Color of comments
  morecomment=[l][\color{magenta}]{\#}
}
% Define style table
\setlength{\heavyrulewidth}{1.5pt}
\setlength{\abovetopsep}{4pt}
\begin{document}
% -------------------------------------------------------------
% Cover
% -------------------------------------------------------------
\author{David Miguel Lozano \ Javier Martínez Riberas}
\title{P2 Self-organizing Maps}
\date{08-10-2016}

\begin{titlepage}
	\centering
	\includegraphics[width=0.16\textwidth]{ubu-logo.png}\par
	\vspace{0.3cm}
	{\scshape\LARGE Universidad de Burgos \par}
	\vfill
	{\scshape\Large Computación Neuronal y Evolutiva \par}
	\HRule{2pt}
	{\huge\bfseries P2: Self-organizing Maps \par}
	\HRule{2pt}
	\\ [0.5cm]
	{Diseñar y entrenar un mapa auto-organizado con una rejilla bidimensional para el agrupamiento de un único conjunto de datos de muestra de tres dimensiones. Estudiando el efecto que tienen una serie de parámetros durante el entrenamiento de este.}
	\vfill
	Estudiantes:\par
	{\Large\scshape David Miguel Lozano \\ Javier Martínez Riberas \par}
	\vfill
	Profesor de la asignatura:\par
	\textsc{Álvaro Herrero Cosío}
	\vfill
	{\large 1º semestre 2016 \par}
\end{titlepage}

% -------------------------------------------------------------
% Contents
% -------------------------------------------------------------
\newpage
\tableofcontents
\begin{appendix}
  %\listoffigures
  %\listoftables
\end{appendix}

% -------------------------------------------------------------
% Body
% -------------------------------------------------------------
\newpage

\section{Introduction}

El objetivo de la práctica es diseñar y entrenar un mapa auto-organizado para una rejilla bidimensional con un único conjunto de datos de muestra de tres dimensiones. 

Se realizará un estudio sobre el impacto que supone variar los siguientes parámetros en el entrenamiento del mapa para el mismo conjunto de datos:

\begin{enumerate}[noitemsep]
	\item Dimensiones de la topología.
	\item Tamaño del vecindario.
	\item Función de topología.
	\item Función de distancia entre neuronas.
\end{enumerate}

\section{Descripción del conjunto de datos}

\begin{figure}[!ht]
	\centering
	\label{fig:patternnet}
	\includegraphics[width=\textwidth]{datos.png}
	\caption{Representación de los datos}
\end{figure}

El conjunto de datos utilizado para esta práctica ha sido generado aleatoriamente mediante la función \lstinline|nngen|. Se ha intentado conseguir un conjunto en donde se diferencien 7 clústeres próximos entre ellos pero que sean linealmente separables.

Los datos han sido generados de la siguiente manera:

\begin{lstlisting}
nngenc([0 5; 0 5; 0 5], 7, 200, 0.30);
\end{lstlisting}

El primer parámetro (\lstinline|bounds|) se corresponde con los rangos del espacio en donde generar los datos. Nuestros datos estarán en un espacio de tres dimensiones en el rago [0, 5] en cada dimensión.

El segundo parámetro (\lstinline|clusters|) es el número de clústeres a generar. Generaremos 7 clústeres linealmente diferenciables.

El tercer parámetro (\lstinline|points|) es el número de puntos por clúster. Nuestros clústeres tendrán 200 puntos cada uno.

Por último se indica la desviación estándar de los clústeres (\lstinline|std_dev|). Asignamos una desviación de un 30\% para que los clústeres no estén muy localizados y su agrupamiento no sea tan trivial.

Una vez generados los datos deseados, los hemos guardado en un fichero CSV para su posterior explotación en el estudio. 

\section{Descripción del procedimiento}

Para automatizar el estudio lo máximo posible, se ha realizado un script que entrena un mapa auto-organizado variando los parámetros de dimensiones de la topología, tamaño del vecindario, función de topología y función de distancia entre neuronas. 

Por cada configuración, se generan las siguientes figuras y se guardan como imágenes png:

\begin{itemize}[noitemsep]
	\item \lstinline|plotsomnd|: en esta representación se puede observar la topología del SOM (\textit{self-organizing map}), las conexiones directas entre neuronas y la distancia entre estas. Las neuronas se dibujan como hexágonos azules, las conexiones mediante líneas rojas y las distancias se representan mediante el coloreado de las parcelas, correspondiendo el color amarillo a distancias cortas y el negro a distancias grandes. \citep{matlab:plotsomnd}
	\item \lstinline|plotsomhits|: en esta representación se visualiza el número de datos para los que se está activando cada neurona (el número de vectores de entrada que clasifica). Se dibuja la topología del SOM y en cada parcela, correspondiente a una neurona, se muestra el número total así como un hexágono azul de tamaño relativo a este. \citep{matlab:plotsomhits}
	\item \lstinline|plotsompos|: muestra un gráfico en 2D en donde se visualizan la posición de las neuronas (puntos azules), las conexiones entre estas (líneas rojas) y las posiciones de los datos (puntos verdes). Permite visualizar cómo el SOM clasifica el espacio de entrada según evoluciona el entrenamiento. \citep{matlab:plotsompos}
\end{itemize}

Los comandos \lstinline|plotsomnd| y \lstinline|plotsomhits| están limitados a topologías \lstinline|hextop| o \lstinline|gridtop|, no pudiendo ser utilizados con \lstinline|randtop|. 

\emph{*Todo el código generado en esta práctica se encuentra disponible en el siguiente repositorio: 
\href{https://github.com/davidmigloz/neuronal-networks/tree/master/P2\_SelfOrganizingMap}{P2\_SelfOrganizingMap}.}

\section{Estudio}

Antes de comenzar el estudio, se jugó un poco con los datos para tantear qué valores podían merecer la pena estudiar. Finalmente elegimos los siguientes parámetros:

\begin{itemize}[noitemsep]
	\item  Función de distancia entre neuronas:
	\begin{enumerate}[noitemsep]
		\item \lstinline|dist|: distancia euclídea.
		\item \lstinline|linkdist|: distancia en número de enlaces.
		\item \lstinline|mandist|: distancia de Manhattan.
		\item \lstinline|boxdist|: distancia cuadrada.
	\end{enumerate}
	\item Función de topología:
	\begin{enumerate}[noitemsep]
		\item \lstinline|gridtop|: rejilla cuadrada.
		\item \lstinline|hextop|: rejilla hexagonal.
		\item \lstinline|randtop|: rejilla aleatoria.
	\end{enumerate}	
\end{itemize}
\begin{enumerate}[noitemsep]
	\item Dimensiones de la topología: de 7 a 10 con incrementos de 1.
	\item Tamaño del vecindario: de 2 a 7 con incrementos de 1.
\end{enumerate}

\subsection{Criterio}

De todas las combinaciones anteriores (288 casos) se seleccionaron manualmente los mejores representantes de cada función de topología y función de distancia, quedándonos con 12 casos a analizar.

La principal limitación que hemos tenido en esta práctica ha sido el no tener un parámetro que nos indicase cómo de bueno o malo era cada caso. Por ello, la clasificación se ha realizado de forma manual (y por tanto con cierta componente de subjetividad).

Para el análisis, nos hemos basado sobretodo en las representaciones \lstinline|plotsomnd| y \lstinline|plotsomhits|. Ya que, nos proporcionan información de calidad sobre cómo se han distribuido las neuronas sobre los datos. En cambio, \lstinline|plotsompos| al realizar una representación en 
dos dimensiones de datos tridimensionales puede generar confusión.

A continuación se exponen dos ejemplos de un mejor y un peor caso según el criterio seguido. 

Cómo vemos en el 'caso malo', no existe una diferenciación clara entre los siete clústeres. Tanto en distancias entre neuronas como en datos captados por cada una. Además, existen neuronas muertas (sin datos o muy pocos) que no favorecen la distinción de ninguna clase.

Por el contrario, en el 'caso bueno' podemos observar una clara diferenciación de los siete clústeres. Vemos como la distancia entre las neuronas fronterizas entre clases es alta, mientras que la distancia entre neuronas de la misma clase es corta. Además, las neuronas muertas se encuentran en fronteras, lo cual favorece la clasificación.

\begin{figure}[!ht]
	\centering
	\label{fig:patternnet}
	\includegraphics[width=\textwidth]{caso-malo.jpg}
	\caption{Caso malo}
\end{figure}

\begin{figure}[!ht]
	\centering
	\label{fig:patternnet}
	\includegraphics[width=\textwidth]{caso-bueno.jpg}
	\caption{Caso bueno}
\end{figure}

\subsection{Resultados}

Las imágenes de los resultados de las 288 ejecuciones con las diferentes configuraciones se encuentran ordenadas en el repositorio de la práctica: \href{https://github.com/davidmigloz/neuronal-networks/tree/master/P2\_SelfOrganizingMap/img}{Resultados}. No se incluyen en el informe por no aumentar demasiado la longitud de este.

En la siguiente tabla se resumen parte de nuestras observaciones de los resultados, calificando cada caso como 'malo', 'medio' o 'bueno'.

\begin{table}[!ht]
\centering
\begin{tabular}{*3c}
\toprule
Rejilla & Distancia & Resultado \\ 
\midrule
gridtop & dist & medio \\ 
        & linkdist & bueno \\ 
        & mandist & medio \\ 
	      & boxdist & malo \\ 
hextop & dist & bueno \\ 
       & linkdist & medio \\ 
	     & mandist & error \\ 
			 & boxdist & medio \\ 
randtop & dist & medio \\ 
   	 	  & linkdist & malo \\ 
				& mandist & medio \\ 
				& boxdist & malo \\ 
\bottomrule
\end{tabular} 
\caption{Resumen de los resultados}
\label{tab:results}
\end{table}


\subsection{Resultados reseñables}





\section{Conclusiones}

Reiterar que el análisis ha sido realizado de forma manual con una cierta componente de subjetividad. No se poseía ningún parámetro (cómo en la práctica anterior) que nos permitiese clasificar los casos objetivamente y de forma automática.

A continuación exponemos nuestras conclusiones sobre cada parámetro.
 
\begin{itemize}[noitemsep]
	\item \textbf{Dimensiones de la topología:} según aumentamos el número de neuronas baja, por lo general, la distancia entre estas. Aparecen más neuronas muertas en las regiones fronterizas distantes. Y cada neurona se especializa en un conjunto menor de datos, pero aparecen algunos problemas en la clasificación de clases con fronteras cercanas.
	\item \textbf{Tamaño del vecindario:} vemos que es recomendable ampliar el tamaño del vecindario según se amplía las dimensiones de la topología. Pero no hemos encontrado ninguna relación directa del efecto de ampliar el tamaño del vecindario con una dimensión de la topología fija.
	\item \textbf{Función de topología:} 
	\begin{itemize}[noitemsep]
		\item \lstinline|gridtop|: ha proporcionado unos resultados bastante constantes, obteniendo sus mejores resultados con la función de distancia \lstinline|linkdist|. En líneas generales, han sido algo peores que con \lstinline|hextop|.
		\item \lstinline|hextop|: en general nos ha proporcionado buenos resultados. Sin embargo, utilizando la distancia de Manhattan obtenemos resultados erróneos (las neuronas se distribuyen como si se tratase de una topología lineal).
		\item \lstinline|randtop|: en primer lugar, comentar que sólo se ha podido representar con \lstinline|plotsompos|, lo cual ha dificultado el análisis. En líneas generales, ha sido la función que peores resultados nos ha proporcionado. Hemos observado mucha variabilidad entre ejecuciones. En algunos casos el ajuste era correcto, pero en otros obteníamos varias neuronas aisladas en zonas aleatorias. Creemos que si el número de vecinos fuese mayor de 0 se podrían obtener mejores resultados.		
	\end{itemize}
	\item \textbf{Función de distancia entre neuronas:} los resultados son muy dependientes de la topología. Aunque observamos resultados algo mejores con distancias euclídeas y distancias de número de enlaces.
\end{itemize}


% -------------------------------------------------------------
% Bibliography
% -------------------------------------------------------------
\newpage
\bibliography{citations}
\bibliographystyle{plainnat}

\end{document}